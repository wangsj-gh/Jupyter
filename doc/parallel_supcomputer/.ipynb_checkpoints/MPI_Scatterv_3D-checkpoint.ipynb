{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "executive-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset:\n",
    "    def __init__(self, in_file):\n",
    "        self.in_file = in_file  # Tiff或者ENVI文件\n",
    "\n",
    "        dataset = gdal.Open(self.in_file)\n",
    "        self.XSize = dataset.RasterXSize  # 网格的X轴像素数量\n",
    "        self.YSize = dataset.RasterYSize  # 网格的Y轴像素数量\n",
    "        self.Bands = dataset.RasterCount  # 波段数\n",
    "        self.GeoTransform = dataset.GetGeoTransform()  # 投影转换信息\n",
    "        self.ProjectionInfo = dataset.GetProjection()  # 投影信息\n",
    "    \n",
    "    def get_data(self):\n",
    "        #band: 读取第几个通道的数据\n",
    "        get_dataset = gdal.Open(self.in_file)\n",
    "        data = get_dataset.ReadAsArray(0,0,self.XSize,self.YSize)\n",
    "        return data\n",
    "\n",
    "    def get_lon_lat_minmax(self):\n",
    "        #获取经纬度信息\n",
    "        gtf = self.GeoTransform\n",
    "        x_range = range(0, self.XSize)\n",
    "        y_range = range(0, self.YSize)\n",
    "        x, y = np.meshgrid(x_range, y_range)\n",
    "        longitude = gtf[0] + x * gtf[1] + y * gtf[2]\n",
    "        latitude = gtf[3] + x * gtf[4] + y * gtf[5]\n",
    "        return longitude,latitude \n",
    "\n",
    "def func(x, m1, m2, m3, m4, m5, m6):\n",
    "    return m1 + m2 /(1 + np.exp(-m3 * (x-m4))) - m2/(1 + np.exp(-m5 * (x-m6)))\n",
    "\n",
    "#注意初值\n",
    "def get_param(yData):\n",
    "    xData=np.linspace(1, 365, 92)\n",
    "    Parameters, pcov = curve_fit(func, xData, yData, p0=[5,40,0.1,140,0.1,270], maxfev=100000000)\n",
    "    #method='trf'\n",
    "    return Parameters\n",
    "\n",
    "def fitting(yData):\n",
    "    result=np.array(list(map(get_param,yData)))\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    nprocs = comm.Get_size()\n",
    "    \n",
    "    if rank == 0:\n",
    "        # dir_path = r\"D:\\Desktop\\mypaper\\data\"\n",
    "        # filename = \"gee-LAI-108.tif\"\n",
    "        \n",
    "        dir_path = r\"D:\\Desktop\\cloud-compute\\USA\"\n",
    "        filename = \"gee-LAI-USA-0000006912-0000055296.tif\"\n",
    "        \n",
    "        # dir_path = r\"D:\\Desktop\\cloud-compute\\2015-lai-500r\"\n",
    "        # filename = \"source-LAI-2015y-500r-0000034560-0000034560(1).tif\"\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        data_path = Dataset(file_path)\n",
    "        sendbuf = data_path.get_data( ).transpose(1,2,0)\n",
    "        lon,lat = data_path.get_lon_lat_minmax()\n",
    "        sendbuf = np.ascontiguousarray(sendbuf)\n",
    "\n",
    "        ## sendbuf = np.random.random((13,12,10))\n",
    "        colum2=sendbuf.shape[1]\n",
    "        colum3=sendbuf.shape[2]\n",
    "        \n",
    "        ##each nprocess total number: the size of each sub-task\n",
    "        ave, res = divmod(sendbuf.size, nprocs*colum2*colum3)\n",
    "        ave1, res1 = divmod(res, colum2*colum3)\n",
    "        each_nprocess_row = np.array([ave + 1 if p < ave1 else ave  for p in range(nprocs)])\n",
    "        total_number = each_nprocess_row*colum2*colum3\n",
    "        \n",
    "        ##each nprocess star index: the starting index of each sub-task\n",
    "        star_index = np.array([sum(total_number[:p]) for p in range(nprocs)])\n",
    "\n",
    "    else:\n",
    "        sendbuf = None\n",
    "        star_index = None\n",
    "        colum2=None\n",
    "        colum3=None\n",
    "        ## initialize on worker processes\n",
    "        total_number = np.zeros(nprocs, dtype=np.int)\n",
    "        each_nprocess_row = np.zeros(nprocs, dtype=np.int)\n",
    "\n",
    "    ##broadcast total_number,each_nprocess_row\n",
    "    comm.Bcast(total_number, root=0)\n",
    "    comm.Bcast(each_nprocess_row, root=0)\n",
    "    colum2=comm.bcast(colum2, root=0)\n",
    "    colum3=comm.bcast(colum3, root=0)\n",
    "    \n",
    "    ##initialize recvbuf on all processes\n",
    "    recvbuf = np.zeros((each_nprocess_row[rank],colum2,colum3))\n",
    "    comm.Scatterv([sendbuf, total_number, star_index, MPI.FLOAT], recvbuf, root=0)\n",
    "\n",
    "  \n",
    "    print('After Scatterv, process {} has data:'.format(rank))\n",
    "    print(recvbuf.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
