{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu time: 391.8570840358734\n",
      "gpu time: 0.287822961807251\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#gpu\n",
    "@cuda.jit\n",
    "def process_gpu(img,channels):\n",
    "#     tx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "#     ty = cuda.blockIdx.y * cuda.blockDim.y  +cuda.threadIdx.y\n",
    "    tx, ty = cuda.grid(2)\n",
    "    for k in range(channels):\n",
    "        color = img[tx,ty][k]*2+30\n",
    "        if color >255:\n",
    "            img[tx,ty][k]=255\n",
    "        elif color<0:\n",
    "            img[tx,ty][k]=0\n",
    "        else:\n",
    "            img[tx,ty][k]=color\n",
    "\n",
    "#cpu   \n",
    "def process_cpu(img):\n",
    "    rows,cols,channels=img.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            for k in range(channels):\n",
    "                color=img[i,j][k]*2+30\n",
    "                if color>255:\n",
    "                    img[i,j][k]=255\n",
    "                elif color<0:\n",
    "                    img[i,j][k]=0\n",
    "                else:\n",
    "                    img[i,j][k]=color\n",
    "    return img  \n",
    "           \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    img=cv2.imread('D:/Desktop/20210817203252.jpg')\n",
    "#     img=cv2.imread('D:/Desktop/ii.jfif')\n",
    "    rows,cols,channels = img.shape\n",
    "    start_cpu = time.time()\n",
    "    result_cpu = process_cpu(img)\n",
    "    end_cpu = time.time()\n",
    "    print('cpu time:',end_cpu-start_cpu)\n",
    "    \n",
    "    #GPU function \n",
    "    dImg = cuda.to_device(img)\n",
    "    threadsperblock = (16,16)\n",
    "    blockspergrid_x = int(math.ceil(rows/threadsperblock[0]))\n",
    "    blockspergrid_y = int(math.ceil(cols/threadsperblock[1]))\n",
    "    blockspergrid = (blockspergrid_x,blockspergrid_y)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    start_gpu = time.time()\n",
    "    process_gpu[blockspergrid,threadsperblock](dImg,channels)\n",
    "    cuda.synchronize()\n",
    "    end_gpu = time.time()\n",
    "    dst_gpu=dImg.copy_to_host()\n",
    "    print('gpu time:',end_gpu-start_gpu)\n",
    "    \n",
    "    #save\n",
    "    cv2.imwrite('D:/Desktop/cpu.jpg',result_cpu)\n",
    "    cv2.imwrite('D:/Desktop/gpu.jpg',dst_gpu)\n",
    "    print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5945, 9054, 3)\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "def process_cpu(img):\n",
    "    rows,cols,channels=img.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            for k in range(channels):\n",
    "                color=img[i,j,k]*2+30\n",
    "                if color>255:\n",
    "                    img[i,j,k]=255\n",
    "                elif color<0:\n",
    "                    img[i,j,k]=0\n",
    "                else:\n",
    "                    img[i,j,k]=color\n",
    "    return img  \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    img=cv2.imread('D:/Desktop/20210817203252.jpg')\n",
    "#     img=cv2.imread('C:/Users/student/Desktop/2017111008465240.jpg')\n",
    "    rows,cols,channels = img.shape \n",
    "    print(img.shape)\n",
    "#     start_cpu = time.time()\n",
    "#     result_cpu = process_cpu(img)\n",
    "#     end_cpu = time.time()\n",
    "#     cv2.imwrite('D:/Desktop/cpu.jpg',result_cpu)\n",
    "#     print('cpu time:',end_cpu-start_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu time: 0.39519309997558594\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def process_gpu(img,channels):\n",
    "    tx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    ty = cuda.blockIdx.y * cuda.blockDim.y  +cuda.threadIdx.y\n",
    "\n",
    "    for i in range(channels):\n",
    "        color = img[tx,ty,i]*2+30\n",
    "        if color >255:\n",
    "            img[tx,ty,i]=255\n",
    "        elif color<0:\n",
    "            img[tx,ty,i]=0\n",
    "        else:\n",
    "            img[tx,ty,i]=color\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    img=cv2.imread('D:/Desktop/20210817203252.jpg')\n",
    "#     img=cv2.imread('C:/Users/student/Desktop/aa.jpg')\n",
    "    rows,cols,channels = img.shape \n",
    "        #GPU function \n",
    "    dImg = cuda.to_device(img)\n",
    "    threadsperblock = (16,16)\n",
    "    blockspergrid_x = int(math.ceil(rows/threadsperblock[0]))\n",
    "    blockspergrid_y = int(math.ceil(cols/threadsperblock[1]))\n",
    "    blockspergrid = (blockspergrid_x,blockspergrid_y)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    start_gpu = time.time()\n",
    "    process_gpu[blockspergrid,threadsperblock](dImg,channels)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    end_gpu = time.time()\n",
    "    dst_gpu=dImg.copy_to_host()\n",
    "#     cv2.imwrite('D:/Desktop/gpu.jpg',dst_gpu)\n",
    "    print('gpu time:',end_gpu-start_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stride GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu time: 0.3008725643157959\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def process_gpu(img,rows,cols,channels):\n",
    "#     tx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "#     ty = cuda.blockIdx.y * cuda.blockDim.y  +cuda.threadIdx.y\n",
    "    tx,ty=cuda.grid(2)\n",
    "    stride_x = cuda.blockDim.x * cuda.gridDim.x\n",
    "    stride_y = cuda.blockDim.y * cuda.gridDim.y\n",
    "    \n",
    "    for i in range(tx,rows,stride_x):\n",
    "        for j in range(ty,cols,stride_y):\n",
    "            for i in range(channels):\n",
    "                color = img[tx,ty,channels]*20+30\n",
    "                if color >255:\n",
    "                    img[tx,ty,channels]=255\n",
    "                elif color<0:\n",
    "                    img[tx,ty,channels]=0\n",
    "                else:\n",
    "                    img[tx,ty,channels]=color\n",
    "              \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    img=cv2.imread('C:/Users/student/Desktop/2017110917545743.jpg')\n",
    "#     img=cv2.imread('C:/Users/student/Desktop/462577165016652039.jpg')\n",
    "#     img=cv2.imread('C:/Users/student/Desktop/2017111008465240.jpg')\n",
    "    rows,cols,channels = img.shape \n",
    "        #GPU function \n",
    "    dImg = cuda.to_device(img)\n",
    "    threadsperblock = (16,16)\n",
    "    blockspergrid_x = int(math.ceil(rows/threadsperblock[0]))\n",
    "    blockspergrid_y = int(math.ceil(cols/threadsperblock[1]))\n",
    "\n",
    "    blockspergrid = (blockspergrid_x,blockspergrid_y)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    start_gpu = time.time()\n",
    "    process_gpu[blockspergrid,threadsperblock](dImg,rows,cols,channels)\n",
    "    cuda.synchronize()\n",
    "    end_gpu = time.time()\n",
    "    dst_gpu=dImg.copy_to_host()\n",
    "    cv2.imwrite('C:/Users/student/Desktop/gpu.jpg',dst_gpu)\n",
    "    print('gpu time:',end_gpu-start_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5945, 9054, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shared GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start cpu\n",
      "cpu time: 0.0\n",
      "start global GPU\n",
      "global GPU time: 26.339080333709717\n",
      "start shared GPU\n",
      "global shared time: 31.999357223510742\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda,float32\n",
    "import numba\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "TPB = 16\n",
    "\n",
    "@numba.jit(nopython = True)\n",
    "def matmul_cpu(A,B,C):\n",
    "    for y in range(B.shape[1]):\n",
    "        for x in range(A.shape[0]):\n",
    "            tmp = 0\n",
    "            for k in range(A.shape[1]):\n",
    "                tmp += A[x,k]*B[k,y]\n",
    "            C[x,y] = tmp\n",
    "\n",
    "@cuda.jit\n",
    "def matmul_gpu(A,B,C):\n",
    "    tx,ty = cuda.grid(2)\n",
    "    if tx < C.shape[0] and ty < C.shape[1]:\n",
    "        tmp = 0\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[tx,k]*B[k,ty]\n",
    "        C[tx,ty] = tmp\n",
    "    \n",
    "@cuda.jit\n",
    "def matmul_shared_men(A,B,C):\n",
    "    sA = cuda.shared.array(shape=(TPB,TPB),dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB,TPB),dtype=float32)\n",
    "    x,y = cuda.grid(2)\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    if x>=C.shape[0] and y >=C.shape[1]:\n",
    "        return\n",
    "    \n",
    "    tmp=0\n",
    "    for i in range(int(A.shape[1]/TPB)):\n",
    "        sA[tx,ty] = A[x,ty+i*TPB]\n",
    "        sB[tx,ty] = B[tx+i*TPB,y]\n",
    "        cuda.syncthreads()\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx,j]*sB[j,ty]\n",
    "        cuda.syncthreads()\n",
    "    C[x,y] = tmp\n",
    "    \n",
    "A = np.full((TPB*500,TPB*500),3,np.float)\n",
    "B = np.full((TPB*500,TPB*500),4,np.float)\n",
    "C_cpu = np.full((A.shape[0],B.shape[1]),0,np.float)\n",
    "\n",
    "print('start cpu')\n",
    "start_cpu = time.time()\n",
    "# matmul_cpu(A,B,C_cpu)\n",
    "print('cpu time:',time.time()-start_cpu)\n",
    "\n",
    "##########################start GPU###################################\n",
    "A_global_mem = cuda.to_device(A)\n",
    "B_global_mem = cuda.to_device(B)\n",
    "\n",
    "C_global_mem = cuda.device_array((A.shape[0],B.shape[1]))\n",
    "C_shared_mem = cuda.device_array((A.shape[0],B.shape[1]))\n",
    "\n",
    "threadsperblock = (TPB,TPB)\n",
    "blockspergrid_x = int(math.ceil(A.shape[0]/threadsperblock[0]))\n",
    "blockspergrid_y = int(math.ceil(B.shape[1]/threadsperblock[1]))\n",
    "blockspergrid = (blockspergrid_x,blockspergrid_y)\n",
    "\n",
    "print('start global GPU')\n",
    "start_global_gpu = time.time()\n",
    "matmul_gpu[blockspergrid,threadsperblock](A_global_mem,B_global_mem,C_global_mem)\n",
    "cuda.synchronize()\n",
    "print('global GPU time:',time.time()-start_global_gpu)\n",
    "C_global_gpu = C_global_mem.copy_to_host()\n",
    "\n",
    "print('start shared GPU')\n",
    "start_shared_gpu = time.time()\n",
    "matmul_shared_men[blockspergrid,threadsperblock](A_global_mem,B_global_mem,C_shared_mem)\n",
    "cuda.synchronize()\n",
    "print('global shared time:',time.time()-start_shared_gpu)\n",
    "C_shared_gpu = C_shared_mem.copy_to_host()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 8000)\n",
      "[96000. 96000. 96000.]\n"
     ]
    }
   ],
   "source": [
    "print(C_global_gpu.shape)\n",
    "print(C_global_gpu[0,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 8000)\n",
      "[96000. 96000. 96000.]\n"
     ]
    }
   ],
   "source": [
    "print(C_shared_gpu.shape)\n",
    "print(C_shared_gpu[0,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print((C_shared_gpu-C_global_gpu).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
