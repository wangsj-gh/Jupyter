{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2bf33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/bin/sh\n",
    "\n",
    "# cd ~\n",
    "# touch .netrc\n",
    "# echo \"machine urs.earthdata.nasa.gov login wangshujian password wsj821100\" > .netrc\n",
    "# chmod 0600 .netrc\n",
    "\n",
    "# cd ~\n",
    "# touch .urs_cookies\n",
    "\n",
    "# wget -P /mnt/d/Desktop/download --load-cookies ~/.urs_cookies --save-cookies ~/.urs_cookies --auth-no-challenge=on --keep-session-cookies --content-disposition -i /mnt/d/Desktop/sichuan1.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49a482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from shapely.ops import orient\n",
    "amapa = geopandas.read_file(\"D:\\Desktop\\sichuan1.geojson\") \n",
    "amapa.geometry = amapa.geometry.apply(orient, args=(1,))\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "base = world[world.continent == 'South America'].plot(color='white', edgecolor='black', figsize  = (7, 7))\n",
    "ax= amapa.plot(ax=base, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2f2bc10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bd376cf21f40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# read file size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mgranule_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'granule_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgranules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'g' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import pandas as pd\n",
    "\n",
    "doi = '10.3334/ORNLDAAC/1907'# GEDI L4A DOI \n",
    "\n",
    "# CMR API base url\n",
    "cmrurl='https://cmr.earthdata.nasa.gov/search/' \n",
    "\n",
    "doisearch = cmrurl + 'collections.json?doi=' + doi\n",
    "concept_id = requests.get(doisearch).json()['feed']['entry'][0]['id']\n",
    "\n",
    "geojson = {\"shapefile\": (\"amapa.geojson\", amapa.geometry.to_json(), \"application/geo+json\")}\n",
    "\n",
    "page_num = 1\n",
    "page_size = 2000 # CMR page size limit\n",
    "\n",
    "granule_arr = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "     # defining parameters\n",
    "    cmr_param = {\n",
    "        \"collection_concept_id\": concept_id, \n",
    "        \"page_size\": page_size,\n",
    "        \"page_num\": page_num,\n",
    "        \"simplify-shapefile\": 'true' # this is needed to bypass 5000 coordinates limit of CMR\n",
    "    }\n",
    "    \n",
    "    granulesearch = cmrurl + 'granules.json'\n",
    "    response = requests.post(granulesearch, data=cmr_param, files=geojson)\n",
    "    granules = response.json()['feed']['entry']\n",
    "    \n",
    "    \n",
    "    if granules:\n",
    "        for g in granules:\n",
    "            granule_url = ''\n",
    "            granule_poly = ''\n",
    "            # read file size\n",
    "            granule_size = float(g['granule_size']) \n",
    "            \n",
    "            # reading bounding geometries\n",
    "            if 'polygons' in g:\n",
    "                polygons= g['polygons']\n",
    "                multipolygons = []\n",
    "                for poly in polygons:\n",
    "                    i=iter(poly[0].split (\" \"))\n",
    "                    ltln = list(map(\" \".join,zip(i,i)))\n",
    "                    multipolygons.append(Polygon([[float(p.split(\" \")[1]), float(p.split(\" \")[0])] for p in ltln]))\n",
    "                granule_poly = MultiPolygon(multipolygons)\n",
    "            \n",
    "            # Get URL to HDF5 files\n",
    "            for links in g['links']:\n",
    "                if 'title' in links and links['title'].startswith('Download'):\n",
    "                    granule_url = links['href']\n",
    "            granule_arr.append([granule_url, granule_size, granule_poly])\n",
    "               \n",
    "        page_num += 1\n",
    "    else: \n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# adding bound as the last row into the dataframe\n",
    "# we will use this later in the plot\n",
    "granule_arr.append(['amapa', 0, amapa.geometry.item() ]) \n",
    "\n",
    "# creating a pandas dataframe\n",
    "l4adf = pd.DataFrame(granule_arr, columns=[\"granule_url\", \"granule_size\", \"granule_poly\"])\n",
    "\n",
    "# Drop granules with empty geometry\n",
    "l4adf = l4adf[l4adf['granule_poly'] != '']\n",
    "\n",
    "print (\"Total granules found: \", len(l4adf.index)-1 )\n",
    "print (\"Total file size (MB): \", l4adf['granule_size'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c23913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "gdf = geopandas.GeoDataFrame(l4adf, geometry=l4adf.granule_poly)\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "base = world.plot(color='white', edgecolor='black', figsize  = (7, 7))\n",
    "\n",
    "# last row contains the bounding box (Red)\n",
    "ax= gdf[-1:].plot(ax=base, color='red', edgecolor='red', alpha=0.2)\n",
    "\n",
    "# all but the last row contains granule bounding geometry (Green)\n",
    "ax= gdf[:-1].plot(ax=base, color='green', edgecolor='green', alpha=0.2)\n",
    "\n",
    "minx, miny, maxx, maxy = gdf[-1:].geometry.total_bounds\n",
    "ax.set_xlim(minx-0.25, maxx+0.25)\n",
    "ax.set_ylim(miny-0.25, maxy+0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7df0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "l4a_granules = l4adf[:-1].drop_duplicates(subset=['granule_url'])\n",
    "l4a_granules.to_csv('D:\\Desktop\\sichuan.txt', columns = ['granule_url'], index=False, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
